---
last_updated: '1 May 2025'
bugs:
  - name: PG Splitting/Merging Causes OSD Out-Of-Memory
    description: A bug in the PG splitting and merging code can cause the OSD to go out-of-memory, a condition which persists even after restart. Offline tools are available in fixed releases to workaround the issue. See https://tracker.ceph.com/issues/53729.
    recommendation: Do not change pg_num for any pool until after upgrade to a fixed release. Disable the pg autoscaler. Fixed in v16.2.11 and v17.2.4.
    severity: high
    affected_versions:
      - 15.2.*
      - 16.2.[0-10]
      - 17.2.[0-3]
  - name: Pacific Broken Hotfixes
    description: Version 16.2.11 has a bug in ceph-volume osd activation, which was meant to be hotfixed in 16.2.12 but that release was built incorrectly, including changes which did not pass the rigorous QA testing.
    severity: high
    recommendation: It is recommended to upgrade to version 16.2.13 or later.
    affected_versions:
      - 16.2.[11-12]
  - name: Squid deployed OSDs are crashing
    description: The issue affects only newly deployed OSDs using Squid, while previously deployed OSDs run fine. It is likely caused by the Elastic Shared Blob implementation introduced in this PR https://github.com/ceph/ceph/pull/53178, and ceph-bluestore-tool repair cannot fix it.
    severity: critical
    recommendation: For now, run "ceph config set osd bluestore_elastic_shared_blobs 0" on any Squid cluster before adding new OSDs. Unfortunately, this will not help OSDs already deployed in Squidâ€”the only known fix for them is redeployment.
    affected_versions:
      - 19.*.*
  - name: BlueStore Potential Corruption
    description: Some versions of Ceph were released with a bug that may cause OSDs to crash and corrupt the on-disk data. Upstream ticket https://tracker.ceph.com/issues/69764
    severity: critical
    recommendation: Upgrade to a fixed version (17.2.9 or 18.2.7) as soon as possible.
    affected_versions:
      - 17.2.8
      - 18.2.5
      - 18.2.6
  - name: S3 DeleteBucketLifecycle Does Not Delete Config
    description:
      The S3 DeleteBucketLifecycle API call fails to actually delete the
      lifecycle configuration from the bucket, causing S3 compatibility issues.
      This is a regression introduced in squid 19.2.3. See
      https://tracker.ceph.com/issues/71083.
    severity: medium
    recommendation:
      Upgrade to a fixed version when available, or avoid using
      DeleteBucketLifecycle API in affected versions.
    affected_versions:
      - 19.2.3
